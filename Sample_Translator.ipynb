{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample Translator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMo6fpMotz4pA8sjqjxXSMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/blog/blob/master/Sample_Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EPZMNka3aKW"
      },
      "source": [
        "## What is all of it about?\n",
        "\n",
        "here we have a simple program to call google translate API, pros and cons can be listed as:\n",
        "\n",
        "\n",
        "*   <font color='green'>Simple and easy to use </font>\n",
        "\n",
        "*   <font color='green'>Running on google cloud so there's no IPBan</font>\n",
        "\n",
        "*   <font color='red'>Unofficial library</font>\n",
        " with plenty of hiccups (can be found [here](https://github.com/lushan88a/google_trans_new))\n",
        "\n",
        "*   last but not the least <font color='red'>\"Limitation on count of chars\"</font>\n",
        "\n",
        "In the following cell first, we clone the source code then make a tiny change to avoid the Error! At the last step, we create a Translator class Instance \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RveiMPR936Mz",
        "outputId": "3c995056-9648-4de5-d13a-d80d9290861e"
      },
      "source": [
        "!git clone https://github.com/lushan88a/google_trans_new.git\n",
        "%cd google_trans_new/\n",
        "!sed -i 's/.constant/constant/g' google_trans_new.py\n",
        "from google_trans_new import google_translator  \n",
        "translator = google_translator()  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'google_trans_new'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 216 (delta 3), reused 2 (delta 0), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (216/216), 98.06 KiB | 1.40 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "/content/google_trans_new\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztzxZDvL_dID"
      },
      "source": [
        "#@title Input Text in English\n",
        "\n",
        "text = 'This is the end. Hold your breath and count to ten!' #@param {type:\"string\"}\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekQCqF789vOg"
      },
      "source": [
        "## Text Normalization and Sentence Tokenizer\n",
        "Your input text which was stored in the 'text' variable now normalizing and tokenizing to become prepare for feeding into to API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_vrl9j7Be4E",
        "outputId": "07550fc5-6aba-409c-c30b-4c5fb53cd8a3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sent_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
        "print()\n",
        "# now loop over each sentence and tokenize it separately\n",
        "for sentence in sent_text:\n",
        "    print('Source Language Sentence: ', sentence)\n",
        "    translate_text = translator.translate(sentence,lang_tgt='fa')  \n",
        "    print('Target Language Sentence: ', translate_text)\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "\n",
            "Source Language Sentence:  This is the end.\n",
            "Target Language Sentence:  این آخرشه. \n",
            "Source Language Sentence:  Hold your breath and count to ten!\n",
            "Target Language Sentence:  نفس خود را نگه دارید و به ده حساب کنید! \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9-BTSuYB5cN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}